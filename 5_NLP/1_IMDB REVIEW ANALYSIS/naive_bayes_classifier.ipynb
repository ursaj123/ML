{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92da47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from time import time \n",
    "import math as m\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaeca073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "punct = string.punctuation\n",
    "stopwords_english = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5ac810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>memory \"The Last Hunt\" stuck since saw 1956 13...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shakespeare fan, appreciate Ken Branagh done b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>privilege watching Scarface big screen beautif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>real classic. shipload sailors trying get town...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Serials short subjects originally shown theate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  polarity\n",
       "0  first think another Disney movie, might good, ...         1\n",
       "1  Put aside Dr. House repeat missed, Desperate H...         0\n",
       "2  big fan Stephen King's work, film made even gr...         1\n",
       "3  watched horrid thing TV. Needless say one movi...         0\n",
       "4  truly enjoyed film. acting terrific plot. Jeff...         1\n",
       "5  memory \"The Last Hunt\" stuck since saw 1956 13...         1\n",
       "6  Shakespeare fan, appreciate Ken Branagh done b...         0\n",
       "7  privilege watching Scarface big screen beautif...         1\n",
       "8  real classic. shipload sailors trying get town...         1\n",
       "9  Serials short subjects originally shown theate...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('imdb_complete.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52579c8",
   "metadata": {},
   "source": [
    "## TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013516fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getkey(dict_, key):\n",
    "    if key in dict_.keys():\n",
    "        return dict_[key]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3818dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, think, anoth, disney, movi, might, goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "      <td>[put, asid, dr, hous, repeat, miss, desper, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[big, fan, stephen, king', work, film, made, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, horrid, thing, tv, needless, say, one,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "      <td>[truli, enjoy, film, act, terrif, plot, jeff, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>memory \"The Last Hunt\" stuck since saw 1956 13...</td>\n",
       "      <td>1</td>\n",
       "      <td>[memori, \"the, last, hunt\", stuck, sinc, saw, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shakespeare fan, appreciate Ken Branagh done b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[shakespear, fan, appreci, ken, branagh, done,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>privilege watching Scarface big screen beautif...</td>\n",
       "      <td>1</td>\n",
       "      <td>[privileg, watch, scarfac, big, screen, beauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>real classic. shipload sailors trying get town...</td>\n",
       "      <td>1</td>\n",
       "      <td>[real, classic, shipload, sailor, tri, get, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Serials short subjects originally shown theate...</td>\n",
       "      <td>1</td>\n",
       "      <td>[serial, short, subject, origin, shown, theate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  polarity  \\\n",
       "0  first think another Disney movie, might good, ...         1   \n",
       "1  Put aside Dr. House repeat missed, Desperate H...         0   \n",
       "2  big fan Stephen King's work, film made even gr...         1   \n",
       "3  watched horrid thing TV. Needless say one movi...         0   \n",
       "4  truly enjoyed film. acting terrific plot. Jeff...         1   \n",
       "5  memory \"The Last Hunt\" stuck since saw 1956 13...         1   \n",
       "6  Shakespeare fan, appreciate Ken Branagh done b...         0   \n",
       "7  privilege watching Scarface big screen beautif...         1   \n",
       "8  real classic. shipload sailors trying get town...         1   \n",
       "9  Serials short subjects originally shown theate...         1   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  [first, think, anoth, disney, movi, might, goo...  \n",
       "1  [put, asid, dr, hous, repeat, miss, desper, ho...  \n",
       "2  [big, fan, stephen, king', work, film, made, e...  \n",
       "3  [watch, horrid, thing, tv, needless, say, one,...  \n",
       "4  [truli, enjoy, film, act, terrif, plot, jeff, ...  \n",
       "5  [memori, \"the, last, hunt\", stuck, sinc, saw, ...  \n",
       "6  [shakespear, fan, appreci, ken, branagh, done,...  \n",
       "7  [privileg, watch, scarfac, big, screen, beauti...  \n",
       "8  [real, classic, shipload, sailor, tri, get, to...  \n",
       "9  [serial, short, subject, origin, shown, theate...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(string, stopwords, stemmer):\n",
    "    '''We can do all the preprocessing in just one step by creating a pipeline\n",
    "    First, we have to make all the words in lowercase,\n",
    "    then we have to tokenize the string,\n",
    "    then we have to remove stopwords and \n",
    "    finally we have to stem all the words.\n",
    "    This is how it will be ready to be analyzed further'''\n",
    "    string  = string.lower()\n",
    "    tokens = re.split('\\s|(?<!\\d)[,.](?!\\d)', string)\n",
    "    clean_tokens = []\n",
    "    for word in tokens:\n",
    "        if word not in stopwords:\n",
    "            clean_tokens.append(word)\n",
    "    \n",
    "    stemmed_words = []\n",
    "    for word in clean_tokens:\n",
    "        stemmed_words.append(stemmer.stem(word))\n",
    "    \n",
    "    preprocessed_array = []\n",
    "    for word in stemmed_words:\n",
    "        if word!='':\n",
    "            preprocessed_array.append(word)\n",
    "            \n",
    "    return preprocessed_array\n",
    "#########################################\n",
    "dataset['preprocessed'] = dataset['text'].apply(lambda x:preprocessing(x, stopwords_english, stemmer))    \n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908fc87b",
   "metadata": {},
   "source": [
    "## BUILDING THE VOCABULARY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8910cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frequency(processed_strings, polarities):\n",
    "    vocab = {}\n",
    "    for string, polarity in zip(processed_strings, polarities):\n",
    "        for word in string:\n",
    "            pair = (word, polarity)\n",
    "            if pair in vocab:\n",
    "                vocab[pair]+=1\n",
    "            else:\n",
    "                vocab[pair] = 1\n",
    "    return vocab\n",
    "#####################################\n",
    "vocab = build_frequency(dataset['preprocessed'], dataset['polarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7c855",
   "metadata": {},
   "source": [
    "## FORMING THE PROBABILITY DICTIONARY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9321c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now building up the probability dictionary\n",
    "'''\n",
    "# example for testing \n",
    "# first testing it on a small dataset and verifying it\n",
    "sample_tweets = [\"I am happy because i am learning NLP\", \"I am happy, not sad\"\n",
    "         ,\"I am sad, i am learning NLP\", \"I am sad, not happy\"]\n",
    "sample_labels = [1,1,0,0]\n",
    "sample_tweets = [tweet.lower() for tweet in sample_tweets]\n",
    "sample_tweets = [re.split('\\s|(?<!\\d)[,.](?!\\d)', tweet) for tweet in sample_tweets]\n",
    "sample_processed_tweets = []\n",
    "for i in range(len(sample_tweets)):\n",
    "    temp = []\n",
    "    for word in sample_tweets[i]:\n",
    "        if word!='':\n",
    "            temp.append(stemmer.stem(word))\n",
    "    sample_processed_tweets.append(temp)\n",
    "sample_vocab = build_frequency(sample_processed_tweets, sample_labels)\n",
    "'''\n",
    "def log_likelihood(sample_vocab):\n",
    "    num_unique_words = 0\n",
    "    num_positive_occurences = 0\n",
    "    num_negative_occurences = 0\n",
    "    #####\n",
    "    unique_words = set()\n",
    "    for key in sample_vocab.keys():\n",
    "        unique_words.add(key[0])\n",
    "        if key[1]==0:\n",
    "            num_negative_occurences+= sample_vocab[key]\n",
    "        else:\n",
    "            num_positive_occurences+= sample_vocab[key]\n",
    "    num_unique_words = len(unique_words)\n",
    "\n",
    "    # building the dictionary (with laplacian smoothing)\n",
    "    sample_prob_dict_lap = {}\n",
    "    for word in unique_words:\n",
    "        sample_prob_dict_lap[(word, 0)] =  (1 + getkey(sample_vocab, (word, 0)))/(num_unique_words + num_negative_occurences)   \n",
    "        sample_prob_dict_lap[(word, 1)] =  (1 + getkey(sample_vocab, (word, 1)))/(num_unique_words + num_positive_occurences)   \n",
    "\n",
    "    likelihood_dict = {}\n",
    "    for word in unique_words:\n",
    "        likelihood_dict[word] = m.log(sample_prob_dict_lap[(word, 1)]/sample_prob_dict_lap[(word, 0)])\n",
    "    \n",
    "    return likelihood_dict\n",
    "            \n",
    "prob_dict = log_likelihood(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e2d50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prob_dict, processed_tweet, log_prior):\n",
    "    # processed_tweet will be a list of stemmed tokens\n",
    "    # positive log_value means a positive tweet and vice_versa\n",
    "    log_value = log_prior # to overcome class imbalance\n",
    "    for word in processed_tweet:\n",
    "        log_value+= getkey(prob_dict, word) \n",
    "    return log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a03d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_positive_tweets = sum(dataset['polarity']==1)\n",
    "num_negative_tweets = sum(dataset['polarity']==0)\n",
    "log_prior = m.log(num_positive_tweets/num_negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "527ba042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet = ['memori', '\"the', 'last', 'hunt\"', 'stuck', 'sinc', 'saw', '1956', '13.', 'movi', 'far', 'ahead', 'other', 'time', 'address', 'treatment', 'nativ', 'environ', 'ever', 'present', 'contrast', 'short', 'long', 'term', 'effect', 'greed', 'relev', 'today', '1956,', 'cinemagraph', 'discuss', 'utmost', 'depth', 'relev', 'top', 'set', 'beauti', 'cinematographi', 'excel', 'memori', 'movi', 'end', 'day'], \n",
      "\n",
      "\n",
      "label = 1\n",
      "log_value = 14.376497091451666\n",
      "\n",
      "\n",
      "\n",
      "tweet = ['put', 'asid', 'dr', 'hous', 'repeat', 'miss', 'desper', 'housew', '(new)', 'watch', 'one', 'know', 'exactli', 'plagu', 'movi', 'never', 'thought', \"i'd\", 'say', 'want', '15', 'minut', 'fame', 'back', '<br', '/><br', '/>script', 'direct', \"can't\", 'say', 'recogn', 'stabl', 'actor', '(the', 'usual', 'suspects)', 'thought', 'herbert', 'marshal', 'class', 'addit', 'sat', 'good', 'cheesi', 'flick', 'boy', 'wrong', 'dullsvil', '<br', '/><br', '/>mi', 'favorit', 'parts:', '\"offic', 'girl\"', 'make', '029', 'keypunch', 'put', 'card', '087', 'sorter', 'lol', '@', '\"the', 'computer\"', \"i'd\", 'like', 'someon', 'identifi', 'next', 'devic', '-', '477', '?', 'even', \"dinosaur'\", 'time', '<br', '/><br', '/>and', 'dinosaur', 'much', 'time', 'wast'], \n",
      "\n",
      "\n",
      "label = 0\n",
      "log_value = -16.913143932788522\n"
     ]
    }
   ],
   "source": [
    "# sample_example\n",
    "index = 5\n",
    "tweet, label = dataset['preprocessed'][index], dataset['polarity'][index] \n",
    "print(f\"tweet = {tweet}, \\n\\n\\nlabel = {label}\")\n",
    "log_value = predict(prob_dict, tweet, log_prior)\n",
    "print(f\"log_value = {log_value}\\n\\n\\n\")\n",
    "\n",
    "index = 1\n",
    "tweet, label = dataset['preprocessed'][index], dataset['polarity'][index] \n",
    "print(f\"tweet = {tweet}, \\n\\n\\nlabel = {label}\")\n",
    "log_value = predict(prob_dict, tweet, log_prior)\n",
    "print(f\"log_value = {log_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3079ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuacry on the training set is 95.45\n"
     ]
    }
   ],
   "source": [
    "# let us check accuracy on this dataset\n",
    "labels = dataset['polarity'].iloc[:].values\n",
    "tweets = dataset['preprocessed'].iloc[:].values\n",
    "accuracy = 0\n",
    "num_examples = labels.shape[0]\n",
    "for index in range(num_examples):\n",
    "    if predict(prob_dict, tweets[index], log_prior)>=0:\n",
    "        accuracy+= labels[index]==1\n",
    "    else:\n",
    "        accuracy+= labels[index]==0\n",
    "accuracy/= num_examples\n",
    "\n",
    "print(f\"Accuacry on the training set is {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca177e4",
   "metadata": {},
   "source": [
    "### Naive Bayes can go wrong due to many reasons, some of them can be - \n",
    "* Word Order changes the meaning of sentence.\n",
    "* Preprocessing step removing something important words which might play important role in determining.\n",
    "* These models can't understand sarcasm(obviously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf983b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7317c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b3189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca577bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
