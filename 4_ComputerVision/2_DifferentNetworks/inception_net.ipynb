{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d04cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8618c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22986f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4):\n",
    "        '''\n",
    "        c1, c2, c3, c4 - (int, tuple, tuple, int)\n",
    "        are the respective channels for each path\n",
    "        '''\n",
    "        super(block, self).__init__()\n",
    "        self.path1 = nn.Conv2d(in_channels=in_channels, out_channels=c1, kernel_size=(1,1))\n",
    "        self.path21 = nn.Conv2d(in_channels=in_channels, out_channels=c2[0], kernel_size=(1,1))\n",
    "        self.path22 = nn.Conv2d(in_channels=c2[0], out_channels=c2[1], kernel_size=(3,3),\n",
    "                               stride=(1,1), padding=(1,1))\n",
    "        self.path31 = nn.Conv2d(in_channels=in_channels, out_channels=c3[0], kernel_size=(1,1))\n",
    "        self.path32 = nn.Conv2d(in_channels=c3[0], out_channels=c3[1], kernel_size=(5,5),\n",
    "                                                    padding=(2,2))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.path4 = nn.Conv2d(in_channels=in_channels, out_channels=c4, kernel_size=(1,1))\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        op1 = self.relu(self.path1(x))\n",
    "        op2 = self.relu(self.path21(x))\n",
    "        op2 = self.relu(self.path22(op2))\n",
    "        op3 = self.relu(self.path31(x))\n",
    "        op3 = self.relu(self.path32(op3))\n",
    "        op4 = self.pool(x)\n",
    "        op4 = self.path4(op4)\n",
    "        return torch.cat([op1, op2, op3, op4], axis=1) # axis=1 is channel axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90c358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 96, 96]             128\n",
      "              ReLU-2           [-1, 64, 96, 96]               0\n",
      "            Conv2d-3           [-1, 96, 96, 96]             192\n",
      "              ReLU-4           [-1, 96, 96, 96]               0\n",
      "            Conv2d-5          [-1, 128, 96, 96]         110,720\n",
      "              ReLU-6          [-1, 128, 96, 96]               0\n",
      "            Conv2d-7           [-1, 16, 96, 96]              32\n",
      "              ReLU-8           [-1, 16, 96, 96]               0\n",
      "            Conv2d-9           [-1, 32, 96, 96]          12,832\n",
      "             ReLU-10           [-1, 32, 96, 96]               0\n",
      "        MaxPool2d-11            [-1, 1, 96, 96]               0\n",
      "           Conv2d-12           [-1, 32, 96, 96]              64\n",
      "================================================================\n",
      "Total params: 123,968\n",
      "Trainable params: 123,968\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 49.57\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 50.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "incep_block = block(in_channels=1, c1=64, c2=(96, 128), c3=(16, 32), c4=32).to(device)\n",
    "summary(incep_block, (1,96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4a2d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_net(nn.Module):\n",
    "    def __init__(self, input_size, layers, num_classes):\n",
    "        # layers will be a list of simply num_blocks, c1, c2, c3, c4\n",
    "        in_channels, height, width = input_size\n",
    "        super(inception_net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=(7,7), \n",
    "                               stride=(2,2) ,padding=(3,3))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64,kernel_size=(1,1))\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=192,kernel_size=(3,3),\n",
    "                              stride=(1,1), padding=(1,1))\n",
    "        \n",
    "        in_channels = 192\n",
    "        conv_layers = []\n",
    "        for i in range(len(layers)):\n",
    "            for j in range(len(layers[i])):\n",
    "                c1, c2, c3, c4 = layers[i][j]\n",
    "                conv_layers.append(block(in_channels, c1, c2, c3, c4))\n",
    "                in_channels = c1 + c2[1] + c3[1] + c4\n",
    "            if i==len(layers)-1: # last layer\n",
    "                conv_layers.append(nn.AvgPool2d(kernel_size=(2,2)))\n",
    "            else:\n",
    "                conv_layers.append(self.pool)\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #print(\"in_channels = \", in_channels)\n",
    "        height = height//(64) # 5 pool layers\n",
    "        width  = width//(64) # 5 pool layers\n",
    "        self.fc = nn.Linear(in_features=in_channels*height*width, out_features=num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv(x))\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19ebf780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]           3,200\n",
      "              ReLU-2           [-1, 64, 48, 48]               0\n",
      "         MaxPool2d-3           [-1, 64, 24, 24]               0\n",
      "         MaxPool2d-4           [-1, 64, 24, 24]               0\n",
      "            Conv2d-5           [-1, 64, 24, 24]           4,160\n",
      "              ReLU-6           [-1, 64, 24, 24]               0\n",
      "            Conv2d-7          [-1, 192, 24, 24]         110,784\n",
      "              ReLU-8          [-1, 192, 24, 24]               0\n",
      "         MaxPool2d-9          [-1, 192, 12, 12]               0\n",
      "        MaxPool2d-10          [-1, 192, 12, 12]               0\n",
      "           Conv2d-11           [-1, 64, 12, 12]          12,352\n",
      "             ReLU-12           [-1, 64, 12, 12]               0\n",
      "           Conv2d-13           [-1, 96, 12, 12]          18,528\n",
      "             ReLU-14           [-1, 96, 12, 12]               0\n",
      "           Conv2d-15          [-1, 128, 12, 12]         110,720\n",
      "             ReLU-16          [-1, 128, 12, 12]               0\n",
      "           Conv2d-17           [-1, 16, 12, 12]           3,088\n",
      "             ReLU-18           [-1, 16, 12, 12]               0\n",
      "           Conv2d-19           [-1, 32, 12, 12]          12,832\n",
      "             ReLU-20           [-1, 32, 12, 12]               0\n",
      "        MaxPool2d-21          [-1, 192, 12, 12]               0\n",
      "           Conv2d-22           [-1, 32, 12, 12]           6,176\n",
      "            block-23          [-1, 256, 12, 12]               0\n",
      "           Conv2d-24          [-1, 128, 12, 12]          32,896\n",
      "             ReLU-25          [-1, 128, 12, 12]               0\n",
      "           Conv2d-26          [-1, 128, 12, 12]          32,896\n",
      "             ReLU-27          [-1, 128, 12, 12]               0\n",
      "           Conv2d-28          [-1, 192, 12, 12]         221,376\n",
      "             ReLU-29          [-1, 192, 12, 12]               0\n",
      "           Conv2d-30           [-1, 32, 12, 12]           8,224\n",
      "             ReLU-31           [-1, 32, 12, 12]               0\n",
      "           Conv2d-32           [-1, 96, 12, 12]          76,896\n",
      "             ReLU-33           [-1, 96, 12, 12]               0\n",
      "        MaxPool2d-34          [-1, 256, 12, 12]               0\n",
      "           Conv2d-35           [-1, 64, 12, 12]          16,448\n",
      "            block-36          [-1, 480, 12, 12]               0\n",
      "        MaxPool2d-37            [-1, 480, 6, 6]               0\n",
      "        MaxPool2d-38            [-1, 480, 6, 6]               0\n",
      "           Conv2d-39            [-1, 192, 6, 6]          92,352\n",
      "             ReLU-40            [-1, 192, 6, 6]               0\n",
      "           Conv2d-41             [-1, 96, 6, 6]          46,176\n",
      "             ReLU-42             [-1, 96, 6, 6]               0\n",
      "           Conv2d-43            [-1, 208, 6, 6]         179,920\n",
      "             ReLU-44            [-1, 208, 6, 6]               0\n",
      "           Conv2d-45             [-1, 16, 6, 6]           7,696\n",
      "             ReLU-46             [-1, 16, 6, 6]               0\n",
      "           Conv2d-47             [-1, 48, 6, 6]          19,248\n",
      "             ReLU-48             [-1, 48, 6, 6]               0\n",
      "        MaxPool2d-49            [-1, 480, 6, 6]               0\n",
      "           Conv2d-50             [-1, 64, 6, 6]          30,784\n",
      "            block-51            [-1, 512, 6, 6]               0\n",
      "           Conv2d-52            [-1, 160, 6, 6]          82,080\n",
      "             ReLU-53            [-1, 160, 6, 6]               0\n",
      "           Conv2d-54            [-1, 112, 6, 6]          57,456\n",
      "             ReLU-55            [-1, 112, 6, 6]               0\n",
      "           Conv2d-56            [-1, 224, 6, 6]         226,016\n",
      "             ReLU-57            [-1, 224, 6, 6]               0\n",
      "           Conv2d-58             [-1, 24, 6, 6]          12,312\n",
      "             ReLU-59             [-1, 24, 6, 6]               0\n",
      "           Conv2d-60             [-1, 64, 6, 6]          38,464\n",
      "             ReLU-61             [-1, 64, 6, 6]               0\n",
      "        MaxPool2d-62            [-1, 512, 6, 6]               0\n",
      "           Conv2d-63             [-1, 64, 6, 6]          32,832\n",
      "            block-64            [-1, 512, 6, 6]               0\n",
      "           Conv2d-65            [-1, 128, 6, 6]          65,664\n",
      "             ReLU-66            [-1, 128, 6, 6]               0\n",
      "           Conv2d-67            [-1, 128, 6, 6]          65,664\n",
      "             ReLU-68            [-1, 128, 6, 6]               0\n",
      "           Conv2d-69            [-1, 256, 6, 6]         295,168\n",
      "             ReLU-70            [-1, 256, 6, 6]               0\n",
      "           Conv2d-71             [-1, 24, 6, 6]          12,312\n",
      "             ReLU-72             [-1, 24, 6, 6]               0\n",
      "           Conv2d-73             [-1, 64, 6, 6]          38,464\n",
      "             ReLU-74             [-1, 64, 6, 6]               0\n",
      "        MaxPool2d-75            [-1, 512, 6, 6]               0\n",
      "           Conv2d-76             [-1, 64, 6, 6]          32,832\n",
      "            block-77            [-1, 512, 6, 6]               0\n",
      "           Conv2d-78            [-1, 112, 6, 6]          57,456\n",
      "             ReLU-79            [-1, 112, 6, 6]               0\n",
      "           Conv2d-80            [-1, 144, 6, 6]          73,872\n",
      "             ReLU-81            [-1, 144, 6, 6]               0\n",
      "           Conv2d-82            [-1, 288, 6, 6]         373,536\n",
      "             ReLU-83            [-1, 288, 6, 6]               0\n",
      "           Conv2d-84             [-1, 32, 6, 6]          16,416\n",
      "             ReLU-85             [-1, 32, 6, 6]               0\n",
      "           Conv2d-86             [-1, 64, 6, 6]          51,264\n",
      "             ReLU-87             [-1, 64, 6, 6]               0\n",
      "        MaxPool2d-88            [-1, 512, 6, 6]               0\n",
      "           Conv2d-89             [-1, 64, 6, 6]          32,832\n",
      "            block-90            [-1, 528, 6, 6]               0\n",
      "           Conv2d-91            [-1, 256, 6, 6]         135,424\n",
      "             ReLU-92            [-1, 256, 6, 6]               0\n",
      "           Conv2d-93            [-1, 160, 6, 6]          84,640\n",
      "             ReLU-94            [-1, 160, 6, 6]               0\n",
      "           Conv2d-95            [-1, 320, 6, 6]         461,120\n",
      "             ReLU-96            [-1, 320, 6, 6]               0\n",
      "           Conv2d-97             [-1, 32, 6, 6]          16,928\n",
      "             ReLU-98             [-1, 32, 6, 6]               0\n",
      "           Conv2d-99            [-1, 128, 6, 6]         102,528\n",
      "            ReLU-100            [-1, 128, 6, 6]               0\n",
      "       MaxPool2d-101            [-1, 528, 6, 6]               0\n",
      "          Conv2d-102            [-1, 128, 6, 6]          67,712\n",
      "           block-103            [-1, 832, 6, 6]               0\n",
      "       MaxPool2d-104            [-1, 832, 3, 3]               0\n",
      "       MaxPool2d-105            [-1, 832, 3, 3]               0\n",
      "          Conv2d-106            [-1, 256, 3, 3]         213,248\n",
      "            ReLU-107            [-1, 256, 3, 3]               0\n",
      "          Conv2d-108            [-1, 160, 3, 3]         133,280\n",
      "            ReLU-109            [-1, 160, 3, 3]               0\n",
      "          Conv2d-110            [-1, 320, 3, 3]         461,120\n",
      "            ReLU-111            [-1, 320, 3, 3]               0\n",
      "          Conv2d-112             [-1, 32, 3, 3]          26,656\n",
      "            ReLU-113             [-1, 32, 3, 3]               0\n",
      "          Conv2d-114            [-1, 128, 3, 3]         102,528\n",
      "            ReLU-115            [-1, 128, 3, 3]               0\n",
      "       MaxPool2d-116            [-1, 832, 3, 3]               0\n",
      "          Conv2d-117            [-1, 128, 3, 3]         106,624\n",
      "           block-118            [-1, 832, 3, 3]               0\n",
      "          Conv2d-119            [-1, 384, 3, 3]         319,872\n",
      "            ReLU-120            [-1, 384, 3, 3]               0\n",
      "          Conv2d-121            [-1, 192, 3, 3]         159,936\n",
      "            ReLU-122            [-1, 192, 3, 3]               0\n",
      "          Conv2d-123            [-1, 384, 3, 3]         663,936\n",
      "            ReLU-124            [-1, 384, 3, 3]               0\n",
      "          Conv2d-125             [-1, 48, 3, 3]          39,984\n",
      "            ReLU-126             [-1, 48, 3, 3]               0\n",
      "          Conv2d-127            [-1, 128, 3, 3]         153,728\n",
      "            ReLU-128            [-1, 128, 3, 3]               0\n",
      "       MaxPool2d-129            [-1, 832, 3, 3]               0\n",
      "          Conv2d-130            [-1, 128, 3, 3]         106,624\n",
      "           block-131           [-1, 1024, 3, 3]               0\n",
      "       AvgPool2d-132           [-1, 1024, 1, 1]               0\n",
      "            ReLU-133           [-1, 1024, 1, 1]               0\n",
      "          Linear-134                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 5,977,530\n",
      "Trainable params: 5,977,530\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 13.23\n",
      "Params size (MB): 22.80\n",
      "Estimated Total Size (MB): 36.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 96, 96)\n",
    "layer1 = [(64, (96, 128), (16, 32), 32), (128, (128, 192), (32, 96), 64)]\n",
    "layer2 = [(192, (96, 208), (16, 48), 64), (160, (112, 224), (24, 64), 64), (128, (128, 256), (24, 64), 64),\n",
    "         (112, (144, 288), (32, 64), 64), (256, (160, 320), (32, 128), 128)]\n",
    "layer3 = [(256, (160, 320), (32, 128), 128), (384, (192, 384), (48, 128), 128)]\n",
    "layers = [layer1, layer2, layer3]\n",
    "num_classes = 10\n",
    "model = inception_net(input_shape, layers, num_classes).to(device)\n",
    "summary(model, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ef7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
