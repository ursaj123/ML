{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da602e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from matplotlib import style\n",
    "from PIL import Image\n",
    "\n",
    "# imports for making models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# taking images as input \n",
    "import os\n",
    "import cv2\n",
    "device = 'cpu' # will change if there will be a GPU accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e00a1",
   "metadata": {},
   "source": [
    "### Taking Images Inputs\n",
    "1. Will specify the paths and directories.\n",
    "2. Will make the dataset simply.\n",
    "3. Will make dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aebace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(images_dir, mask_dir):\n",
    "    data = []\n",
    "    img_list = os.listdir(images_dir)\n",
    "    for i in range(len(img_list)): # len(img_list)\n",
    "        if i%100==0:\n",
    "            print(f\"{i} images processed\")\n",
    "        img_path = os.path.join(images_dir, img_list[i])\n",
    "        mask_path = os.path.join(mask_dir, img_list[i].replace(\".jpg\", \"_mask.jpg\"))\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = np.array(img.resize((256, 256))) # have to put both mask and image on same scale\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        mask = np.array(mask.resize((256, 256))) # have to put both mask and image on same scale\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mask)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "        data.append((img, mask))\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'C:\\\\Users\\\\Ayush\\\\Desktop\\\\Let_us_start_once_again\\\\ComputerVision\\\\ImageSegmentation\\\\CARVANA\\\\train'\n",
    "mask_dir = 'C:\\\\Users\\\\Ayush\\\\Desktop\\\\Let_us_start_once_again\\\\ComputerVision\\\\ImageSegmentation\\\\CARVANA\\\\train_masks'        \n",
    "data = dataset(images_dir, mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd9e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloaders(dataset, batch_size):\n",
    "    # i'm ignoring class imabalnce (if any) in randomly genrated train and test sets\n",
    "    train_data, test_data = torch.utils.data.random_split(dataset, [5000, 88])\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7577c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch(dataloader, batch_size):\n",
    "    for _, batch in enumerate(dataloader, 0):\n",
    "        for i in range(batch_size):\n",
    "            #style.use('ggplot')\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(batch[0][i])\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(batch[1][i], cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader, test_loader = make_dataloaders(data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e13e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch(train_loader, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a[0] = a[0].type(torch.float32)\n",
    "# remember this every fucking time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd691eaa",
   "metadata": {},
   "source": [
    "### Now forming the UNET model\n",
    "* first, we will be forming the block \n",
    "* Then we will construct the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5da56bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(block, self).__init__()\n",
    "        all_layers = []\n",
    "        all_layers.append(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1))\n",
    "        all_layers.append(nn.BatchNorm2d(out_channels))\n",
    "        all_layers.append(nn.ReLU())\n",
    "        \n",
    "        all_layers.append(nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1))\n",
    "        all_layers.append(nn.BatchNorm2d(out_channels))\n",
    "        all_layers.append(nn.ReLU())\n",
    "\n",
    "        self.model = nn.Sequential(*all_layers)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b7cf01c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 38,976\n",
      "Trainable params: 38,976\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 192.00\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 192.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "temp_block = block(in_channels=3, out_channels=64).to(device)\n",
    "summary(temp_block, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7f7f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # downsampling part\n",
    "        self.block1 = block(in_channels=3, out_channels=64)\n",
    "        self.block2 = block(in_channels=64, out_channels=128)\n",
    "        self.block3 = block(in_channels=128, out_channels=256)\n",
    "        self.block4 = block(in_channels=256, out_channels=512)\n",
    "        self.block5 = block(in_channels=512, out_channels=1024)\n",
    "        # upsampling part\n",
    "        self.convt1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block6 = block(in_channels=1024, out_channels=512)\n",
    "        \n",
    "        self.convt2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block7 = block(in_channels=512, out_channels=256)\n",
    "        \n",
    "        self.convt3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block8 = block(in_channels=256, out_channels=128)\n",
    "        \n",
    "        self.convt4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block9 = block(in_channels=128, out_channels=64)\n",
    "        self.final_layer = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x - (3, 256, 256)\n",
    "        # downsampling first\n",
    "        skip1 = self.block1(x) # (64, 256, 256)\n",
    "        skip2 = self.block2(self.pool(skip1)) # (128, 128, 128)\n",
    "        skip3 = self.block3(self.pool(skip2)) # (256, 64, 64)\n",
    "        skip4 = self.block4(self.pool(skip3)) # (512, 32, 32)\n",
    "        op = self.block5(self.pool(skip4)) # (1024, 16, 16)\n",
    "        # upsampling\n",
    "        op = self.convt1(op) # (512, 32, 32)\n",
    "        op = self.block6(torch.cat([skip4, op], 1)) # (512, 32, 32)\n",
    "        \n",
    "        op = self.convt2(op) # (256, 64, 64)\n",
    "        op = self.block7(torch.cat([skip3, op], 1)) # (256, 64, 64)\n",
    "        \n",
    "        op = self.convt3(op) # (128, 128, 128)\n",
    "        op = self.block8(torch.cat([skip2, op], 1)) # (128, 128, 128)\n",
    "        \n",
    "        op = self.convt4(op) # (64, 256, 256)\n",
    "        op = self.block9(torch.cat([skip1, op], 1)) # (64, 256, 256)\n",
    "        \n",
    "        return self.final_layer(op) # (1, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8d6f75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "             block-7         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-8         [-1, 64, 128, 128]               0\n",
      "            Conv2d-9        [-1, 128, 128, 128]          73,856\n",
      "      BatchNorm2d-10        [-1, 128, 128, 128]             256\n",
      "             ReLU-11        [-1, 128, 128, 128]               0\n",
      "           Conv2d-12        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
      "             ReLU-14        [-1, 128, 128, 128]               0\n",
      "            block-15        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-16          [-1, 128, 64, 64]               0\n",
      "           Conv2d-17          [-1, 256, 64, 64]         295,168\n",
      "      BatchNorm2d-18          [-1, 256, 64, 64]             512\n",
      "             ReLU-19          [-1, 256, 64, 64]               0\n",
      "           Conv2d-20          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-21          [-1, 256, 64, 64]             512\n",
      "             ReLU-22          [-1, 256, 64, 64]               0\n",
      "            block-23          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-24          [-1, 256, 32, 32]               0\n",
      "           Conv2d-25          [-1, 512, 32, 32]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-27          [-1, 512, 32, 32]               0\n",
      "           Conv2d-28          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-30          [-1, 512, 32, 32]               0\n",
      "            block-31          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-32          [-1, 512, 16, 16]               0\n",
      "           Conv2d-33         [-1, 1024, 16, 16]       4,719,616\n",
      "      BatchNorm2d-34         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-35         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-36         [-1, 1024, 16, 16]       9,438,208\n",
      "      BatchNorm2d-37         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-38         [-1, 1024, 16, 16]               0\n",
      "            block-39         [-1, 1024, 16, 16]               0\n",
      "  ConvTranspose2d-40          [-1, 512, 32, 32]       2,097,664\n",
      "      BatchNorm2d-41          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-42          [-1, 512, 32, 32]               0\n",
      "           Conv2d-43          [-1, 512, 32, 32]       4,719,104\n",
      "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-45          [-1, 512, 32, 32]               0\n",
      "           Conv2d-46          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-47          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-48          [-1, 512, 32, 32]               0\n",
      "            block-49          [-1, 512, 32, 32]               0\n",
      "  ConvTranspose2d-50          [-1, 256, 64, 64]         524,544\n",
      "      BatchNorm2d-51          [-1, 256, 64, 64]             512\n",
      "             ReLU-52          [-1, 256, 64, 64]               0\n",
      "           Conv2d-53          [-1, 256, 64, 64]       1,179,904\n",
      "      BatchNorm2d-54          [-1, 256, 64, 64]             512\n",
      "             ReLU-55          [-1, 256, 64, 64]               0\n",
      "           Conv2d-56          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-57          [-1, 256, 64, 64]             512\n",
      "             ReLU-58          [-1, 256, 64, 64]               0\n",
      "            block-59          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-60        [-1, 128, 128, 128]         131,200\n",
      "      BatchNorm2d-61        [-1, 128, 128, 128]             256\n",
      "             ReLU-62        [-1, 128, 128, 128]               0\n",
      "           Conv2d-63        [-1, 128, 128, 128]         295,040\n",
      "      BatchNorm2d-64        [-1, 128, 128, 128]             256\n",
      "             ReLU-65        [-1, 128, 128, 128]               0\n",
      "           Conv2d-66        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-67        [-1, 128, 128, 128]             256\n",
      "             ReLU-68        [-1, 128, 128, 128]               0\n",
      "            block-69        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-70         [-1, 64, 256, 256]          32,832\n",
      "      BatchNorm2d-71         [-1, 64, 256, 256]             128\n",
      "             ReLU-72         [-1, 64, 256, 256]               0\n",
      "           Conv2d-73         [-1, 64, 256, 256]          73,792\n",
      "      BatchNorm2d-74         [-1, 64, 256, 256]             128\n",
      "             ReLU-75         [-1, 64, 256, 256]               0\n",
      "           Conv2d-76         [-1, 64, 256, 256]          36,928\n",
      "      BatchNorm2d-77         [-1, 64, 256, 256]             128\n",
      "             ReLU-78         [-1, 64, 256, 256]               0\n",
      "            block-79         [-1, 64, 256, 256]               0\n",
      "           Conv2d-80          [-1, 1, 256, 256]              65\n",
      "================================================================\n",
      "Total params: 31,045,441\n",
      "Trainable params: 31,045,441\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 1049.50\n",
      "Params size (MB): 118.43\n",
      "Estimated Total Size (MB): 1168.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = UNET().to(device)\n",
    "summary(model, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c163c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fde94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c477c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb809ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6aa6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d53fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d9f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "segment = Segment().to(device)\n",
    "optimizer = optim.Adam(segment.parameters(),lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "summary(segment,(3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    tic = time()\n",
    "    LOSS = []\n",
    "    for epoch in range(1,epochs+1):\n",
    "        total_loss = 0\n",
    "        for i in range(len(train_loader)):\n",
    "            # shape of images is (-1,3,112,112)\n",
    "            images = (train_loader[i][0][0]/255.0).to(device)\n",
    "            # shape of masks is initially (-1,3,101,101) \n",
    "            masks = (train_loader[i][1][0]/1.0).to(device)\n",
    "            # shape of masks will now be converted to (-1,101,101)\n",
    "            masks = masks.mean(axis=1)\n",
    "            masks[masks>0] = 1.0 # this will convert the all elements=3 as category 1\n",
    "            # forward propoagtaion\n",
    "            model_output = segment(images)\n",
    "            model_output = model_output.reshape(-1,64,64)\n",
    "            loss = criterion(masks,model_output).sum()\n",
    "            total_loss+= loss.item()\n",
    "            # backward propoagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i%100==0:\n",
    "                print('Epoch [{}] ({}/{}), train_loss = {:.4f}, time = {:.2f} sec'.format(epoch, i, len(train_loader), loss.item(), time() - tic ))       \n",
    "        print(\"\\n\")\n",
    "        LOSS.append(total_loss/len(train_loader))\n",
    "    return LOSS\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfafe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = train(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f519da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the training loss\n",
    "plt.plot(range(1, epochs+1), LOSS)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Loss vs NumEpochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "image = (train_loader[0][0][0][1]/255.0).to(device)\n",
    "image = image.reshape(1,3,64,64)\n",
    "\n",
    "model_output = segment(image) # shape is (1,1,64,64)\n",
    "model_output = model_output.reshape(1,64,64)\n",
    "model_output[model_output>=0.5] = 1.0\n",
    "model_output[model_output<0.5] = 0.0\n",
    "print(\"model_output\", model_output.shape)\n",
    "\n",
    "mask = (train_loader[0][1][0][1]/1.0).to(device) # shape is (1,3,64,64)\n",
    "mask = mask.mean(axis=0) # shape is (1,64,64)\n",
    "mask = mask.reshape(1,64,64)\n",
    "print(\"mask\",mask.shape)\n",
    "mask[mask>0] = 1.0\n",
    "\n",
    "print(torch.abs(mask-model_output).sum().item())\n",
    "\n",
    "#fig = plt.figure(figsize=(6,2))\n",
    "image = (image*255).cpu().detach().numpy().reshape(3,64,64)\n",
    "model_output = model_output.cpu().detach().numpy().reshape(64,64)\n",
    "mask = mask.cpu().numpy().reshape(64,64)\n",
    "\n",
    "f, axarr = plt.subplots(nrows=1,ncols=3)\n",
    "plt.sca(axarr[0]); \n",
    "plt.imshow(np.transpose(image,(1,2,0))); plt.title('title 1')\n",
    "plt.sca(axarr[1]); \n",
    "plt.imshow(mask,cmap='gray'); plt.title('title 2')\n",
    "plt.sca(axarr[2]); \n",
    "plt.imshow(model_output,cmap='gray'); plt.title('title 3')\n",
    "plt.show()\n",
    "\n",
    "'''#fig.add_subplot(2,3,1)\n",
    "plt.imshow(np.transpose(image.reshape(3,64,64), (1,2,0)))\n",
    "\n",
    "#fig.add_subplot(2,3,2)\n",
    "plt.imshow(mask.reshape(64,64),cmap='gray')\n",
    "\n",
    "#fig.add_subplot(2,3,3)\n",
    "plt.imshow(model_output.reshape(64,64),cmap='gray')\n",
    "plt.axis('off')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = (train_loader[0][0][0][1]/1.0)\n",
    "image = image.reshape(3,64,64)\n",
    "plt.imshow(np.transpose(image,(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabae27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "image = (train_loader[0][0][0][1]/255.0).to(device)\n",
    "image = image.reshape(1,3,64,64)\n",
    "\n",
    "model_output = segment(image).reshape(64,64).cpu().detach().numpy()\n",
    "model_output[model_output>0.5] = 1.0\n",
    "model_output[model_output<=0.5] = 0.0\n",
    "model_output.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58986f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd738000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc47c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75cb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb8527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3cc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376595be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c93a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c35605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131ce00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b05d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a0ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7f192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1ef5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3b3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6cada7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4751cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0f56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512c430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5777d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab1491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea2f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e5f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30828656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e67849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b80e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3b72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
