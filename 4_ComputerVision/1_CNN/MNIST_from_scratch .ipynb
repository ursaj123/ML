{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7JmEAYozO6xg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27994,
     "status": "ok",
     "timestamp": 1671387414788,
     "user": {
      "displayName": "code",
      "userId": "04595808719497941504"
     },
     "user_tz": -330
    },
    "id": "7JmEAYozO6xg",
    "outputId": "54465b93-fb61-43ae-cc03-1c4071e1bc3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3f7e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3229,
     "status": "ok",
     "timestamp": 1671387509179,
     "user": {
      "displayName": "code",
      "userId": "04595808719497941504"
     },
     "user_tz": -330
    },
    "id": "8ba3f7e8",
    "outputId": "6c0da827-2b72-4f34-9912-41936f3c8a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from time import time\n",
    "\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_qxB5DBIN2xF",
   "metadata": {
    "id": "_qxB5DBIN2xF"
   },
   "source": [
    "# Helpful codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mVVL8RNtdZOX",
   "metadata": {
    "id": "mVVL8RNtdZOX"
   },
   "outputs": [],
   "source": [
    "def dropout_regularizer(X, device, dropout=0.3):\n",
    "    assert 0 <= dropout <= 1# In this case, all elements are dropped out\n",
    "    if dropout == 1:\n",
    "        return torch.zeros(X.shape, dtype=torch.float32, device=device)# In this case, all elements are kept\n",
    "    if dropout == 0:\n",
    "        return X\n",
    "    mask = torch.rand(X.shape, dtype=torch.float32, device=device) > dropout\n",
    "    return torch.multiply(X, mask) / (1.0 - dropout)\n",
    "\n",
    "def relu(x, device):\n",
    "    return torch.maximum(torch.tensor([0], dtype=torch.float32, device=device), x)\n",
    "\n",
    "\n",
    "def init_dense_params(in_nodes, out_nodes, device):\n",
    "    # xavier initialization\n",
    "    params = []\n",
    "    a = math.sqrt(6/(in_nodes + out_nodes))\n",
    "    params.append(torch.tensor(np.random.uniform(-a, a, (in_nodes, out_nodes)), dtype=torch.float32, device=device, requires_grad=True))   \n",
    "    #params.append(torch.Tensor((layers[i], layers[i+1]), requires_grad=True).uniform_(-a, a))\n",
    "    params.append(torch.tensor(np.random.uniform(-a, a, (out_nodes)), dtype=torch.float32, device=device, requires_grad=True))   \n",
    "    #params.append(torch.randn(layers[i+1], dtype = torch.float32, requires_grad=True))\n",
    "    return params\n",
    "\n",
    "def dense_batch(x, params, device, dropout = False): # we will apply dropout only when training is going on\n",
    "    op = x\n",
    "    op = relu(torch.matmul(op, params[0]) + params[1], device)\n",
    "    if dropout:\n",
    "        op = dropout_regularizer(op, device)\n",
    "    return op # shape will be (16, 3)\n",
    "\n",
    "\n",
    "def accuracy(x, y, params, device):\n",
    "    op = dense_batch(x, params, device) # shape is (210, 3)\n",
    "    _, ind = torch.max(op, axis=1)\n",
    "    return torch.sum(ind==y)/y.shape[0]\n",
    "\n",
    "def pred(x, params, device):\n",
    "    op = dense_batch(x, params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Db5kElfdZK9",
   "metadata": {
    "id": "5Db5kElfdZK9"
   },
   "outputs": [],
   "source": [
    "def pad_single_image(x, pad_size, device): # pad just with respect to one image # working fine\n",
    "    '''\n",
    "     pad_size will be a tuple.\n",
    "     remember that x will be of shape (num_channels, height , width),  only be applying zero padding \n",
    "    '''\n",
    "    op = x\n",
    "    num_channels, height, width = x.shape \n",
    "    #print(x.shape)\n",
    "    if pad_size[0]!=0:\n",
    "        pad_vert = torch.zeros((num_channels, pad_size[0], width), dtype=torch.float32, device=device)\n",
    "        #print(\"pad_vert.shape = \", pad_vert.shape)\n",
    "        op = torch.cat((pad_vert, op, pad_vert), axis=1)\n",
    "        #print(\"op = \", op.shape) # shape must be (num_channels, height+2*pad_size[0], width)\n",
    "    if pad_size[1]!=0:\n",
    "        pad_horiz = torch.zeros((num_channels, height+2*pad_size[0],  pad_size[1]), dtype=torch.float32, device=device)\n",
    "        #print(\"pad_horiz.shape = \", pad_horiz.shape)\n",
    "        op = torch.cat((pad_horiz, op, pad_horiz), axis=2)\n",
    "        #print(\"op = \", op.shape) # shape must be (num_channels, height+2*pad_size[0], width+2*pad_size[1])\n",
    "    return op\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pooling a 2D array\n",
    "def pool_arr(x, kernel_size,  stride, mode, device): # works fine\n",
    "    '''\n",
    "    x will be a 2D array\n",
    "    kernel_size will be a tuple\n",
    "    stride will be a tuple\n",
    "    mode will be either 'max' or 'avg'\n",
    "    '''\n",
    "    # let x be of shape (5, 5), kernel be of  shape(2,2), stride be of shape(2, 2)\n",
    "    # so resultant shape must be (2,2)\n",
    "    op = []\n",
    "    for i in range(0, x.shape[0], stride[0]):  \n",
    "        if i+kernel_size[0]<=x.shape[0]:\n",
    "            row = []\n",
    "            for j in range(0, x.shape[1], stride[1]):\n",
    "                if j+kernel_size[1]<=x.shape[1]:\n",
    "                    if mode=='max':\n",
    "                        row.append(torch.max(x[i:i+kernel_size[0], j:j+kernel_size[1]]))\n",
    "                    else: # mode=='avg'\n",
    "                        row.append(torch.mean(x[i:i+kernel_size[0], j:j+kernel_size[1]]))\n",
    "            op.append(torch.stack(row))\n",
    "    return torch.stack(op) # this will be 2D tensor\n",
    "\n",
    "# pooling a 3D image\n",
    "def pool_single_img(x, kernel_size, pad_size, stride ,mode, device): # pool just with respect to one image, works fine\n",
    "    '''\n",
    "    kernel_size will be a tuple\n",
    "    remember this is a parameterless operation to do\n",
    "    '''\n",
    "    x = pad_single_image(x, pad_size, device)\n",
    "    op = torch.stack([pool_arr(x[i], kernel_size, stride, mode, device) for i in range(x.shape[0])])\n",
    "    return op\n",
    "\n",
    "# convolution of a 3D image\n",
    "def conv_single_image(x, params, pad_size, stride, device):\n",
    "    '''\n",
    "    remember params is a list of weights and biases alternatively like [w1, b1, w2, b2, ..., w_out_channels, b_out_channels]\n",
    "    all w_i shape will be (in_channels, _ , _) and b_i will be scalars\n",
    "    '''\n",
    "    x = pad_single_image(x, pad_size, device=device)\n",
    "    out_channels = len(params)//2 # according to the format desired\n",
    "    in_channels, p, q = params[0].shape # in_channels, _, _\n",
    "    op = []\n",
    "    for i in range(out_channels): # output no. of channels \n",
    "        channel = []\n",
    "        for j in range(0, x.shape[1], stride[0]): # x.shape[1] = height\n",
    "            if j+p<=x.shape[1]:\n",
    "                row =[]\n",
    "                for k in range(0, x.shape[2], stride[1]): # x.shape[2] = width\n",
    "                    if k+q<=x.shape[2]:\n",
    "                        kernel, bias = params[2*i], params[2*i +1]\n",
    "                        row.append(torch.sum(torch.multiply(kernel, x[:, j:j+p, k:k+q])) + bias[0])\n",
    "                #print('row = ', row)\n",
    "                #print(\"row.shape = \", torch.stack(row).shape)\n",
    "                channel.append(torch.stack(row)) # 1D \n",
    "        op.append(torch.stack(channel)) # 2D\n",
    "    return torch.stack(op) # 3D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# padding\n",
    "def pad_batch(x, pad_size, device): # works fine\n",
    "    '''\n",
    "    shape of x will be - (batch_size, num_channles, height, width)\n",
    "    '''\n",
    "    op = torch.stack([pad_single_image(x[i], pad_size, device) for i in range(x.shape[0])])\n",
    "    return op\n",
    "\n",
    "# pooling\n",
    "def pool_batch(x, kernel_size, pad_size, stride, mode, device): # works fine\n",
    "    '''\n",
    "    shape of x will be - (batch_size, num_channles, height, width)\n",
    "    '''\n",
    "    op = torch.stack([pool_single_img(x[i], kernel_size, pad_size, stride, mode, device) for i in range(x.shape[0])])\n",
    "    return op\n",
    "\n",
    "\n",
    "# conv forward for a batch \n",
    "def conv_batch(x, params, pad_size, stride, device):\n",
    "    '''\n",
    "    shape of x will be - (batch_size, num_channles, height, width)\n",
    "    '''\n",
    "    op = torch.stack([conv_single_image(x[i], params, pad_size, stride, device) for i in range(x.shape[0])])\n",
    "    return op\n",
    "\n",
    "\n",
    "\n",
    "def init_conv_params(in_channels, out_channels, kernel_size, device):\n",
    "    # xavier initialization for breaking the symmetry and stable training with using \n",
    "    height, width = kernel_size\n",
    "    var = math.sqrt(6/(in_channels + out_channels))\n",
    "    op = []\n",
    "    for i in range(out_channels):\n",
    "        weight = torch.tensor(np.random.uniform(-var, var, (in_channels, height, width)), dtype=torch.float32, device = device, requires_grad=True)   \n",
    "        bias = torch.tensor(np.random.uniform(-var, var, (1)), dtype=torch.float32, device=device, requires_grad=True)\n",
    "        op.append(weight)\n",
    "        op.append(bias)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1492d238",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 3983,
     "status": "ok",
     "timestamp": 1671387593411,
     "user": {
      "displayName": "code",
      "userId": "04595808719497941504"
     },
     "user_tz": -330
    },
    "id": "1492d238",
    "outputId": "3b428064-fdaa-4233-b88d-55d78f89e42b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-da28a100-307e-4011-a34a-d592eb4898c5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da28a100-307e-4011-a34a-d592eb4898c5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-da28a100-307e-4011-a34a-d592eb4898c5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-da28a100-307e-4011-a34a-d592eb4898c5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/MNIST_from_scratch/train.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8534e6",
   "metadata": {
    "id": "5b8534e6"
   },
   "outputs": [],
   "source": [
    "# .values gives the datasets as numpy arrays and when we give them to dataloaders they automatically transform them to tensors\n",
    "dataset = dataset.values\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, (33600, 8400)) # 80% training \n",
    "train_dataloader =  torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391cbfc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "executionInfo": {
     "elapsed": 1027,
     "status": "ok",
     "timestamp": 1671387603835,
     "user": {
      "displayName": "code",
      "userId": "04595808719497941504"
     },
     "user_tz": -330
    },
    "id": "7391cbfc",
    "outputId": "fc6b90dd-7ec9-4b18-efa3-cabc7a96a3c8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAD0CAYAAAAyj7PqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3defzVU/7A8ffRok1aRKUUU4Q0SWihRVqmotJCwkiS0ExlLIU2lUFJthGaUTNUQxQ1leVXaDWYNE0laTFtdu2pyef3xzdv53w+33vde793/Xxfz8djHvM+3/O5n/uu073fe9z3Ocd4nicAAAAAANiOyXQCAAAAAIDsw2QRAAAAABDAZBEAAAAAEMBkEQAAAAAQwGQRAAAAABDAZBEAAAAAEMBkEQAAAAAQELrJojGmmTFmtjFmizHGM8bcm+mcED9jzAnGmD8ZY7YbY34wxmwyxvTNdF6InTHmGGPMMGPMBmPMAWPM58aYx4wxpTOdG+LD+2o4GGPaG2NWHn1P3WyMGZzpnBA/Xo+5zxhzhzFmmTHmO2PM98aYxcaYdpnOC/ErDK/H0E0WRaSMiKwRkTtFZGeGc0ECjDFlRORdEaklIj1F5AwRuVpE1mYyL8TtdhH5g4jcJSJnikhfEekmIo9kMikkhPfVHGeMaSgis0VknojUF5ERIjLWGHNzJvNCQng95r5LROTPItJSRC4QkaUiMscY0zSjWSERoX89Gs/zMp1DyhhjNovIc57njc50LoidMWakiPxWRM7wPO+HTOeDxBhjZonIEc/zulo/Gy8il3ied27mMkNB8L6am4wxL4pITc/zmlg/e1hEunueVzNjiaFAeD2GhzFmlYi86Xne7ZnOBYkJ6+sxjN8sIvd1FZHFIjLBGLPDGLPOGPOwMaZUphNDXBaLSFNjTD0REWPMaSLSXkTmZjQroHBqKiLzfT+bLyI1jDHVMpAPgKOMMceISFkR2ZfpXAC/oplOAMjHrySvBPVlEblMRKqKyBNH/79XBvNCfMaLSAkR+cgY40ne+82zInJfRrMCCqcqEiyR2mn1bU1vOgAsQ0WknIg8k+lEAD8mi8hGx4jINyLS2/O8wyIixpjiIvKSMWaA53nfZjQ7xKqbiNwiIr1FZKXkrT2dICKjReSeDOYFAEBWMMbcInmTxcs9z+M/2iDrMFlENtohIpt/mige9Z+j/19DRJgs5obxIjLR87y/Hm3/2xhTUkT+bIy53/O8gxnMDShsdohIZd/PTrL6AKSZMeYPIjJS8iaKb2U6HyA/rFlENnpPRGoZY+z/mHHG0f/fnP50kKDSIvKj72dHRMQc/R+A9FkiIm19P2snIlv4NgNIP2PMKBEZLiLtmSgim4Xum8Wjxy7UOtosLiKVjTH1RWSv53kbMpcZ4jBORHqIyFPGmEckbz3NOBGZ6nnedxnNDPGYJSJ/MMZsEJF/Sd6Ef7SIzPM870BGM0NceF8NhQkistQYM0ZE/ioiF4rIABEZlNGsEDdej7nPGPOoiPSTvOPBPjHG/PSt/wHP83ZlLjPEqzC8HkN3dIYxpoWILMyn6x3P81qkNxskyhjTSkT+KCLnSN4mDC+JyHDP8/ZnNDHEzBhTWvLOcusqeZsTfSkic0TkXtad5hbeV8PBGNNBRMaKSB3Je1+d6Hke557mGF6Pue/opm/5meJ53vXpzAUFUxhej6GbLAIAAAAACo41iwAAAACAACaLAAAAAIAAJosAAAAAgAAmiwAAAACAgKhHZ0TZrQkp5nle0s6hYxwzh3EMB8YxHBjHcGAcw4FxDAfGMRyijSPfLAIAAAAAApgsAgAAAAACmCwCAAAAAAKYLAIAAAAAApgsAgAAAAACmCwCAAAAAAKYLAIAAAAAApgsAgAAAAACmCwCAAAAAAKKZjoBIFFXXnml0x48eLDGDRs21Pi6665zrnvhhRdSmxgAAAAQAnyzCAAAAAAIYLIIAAAAAAhgsggAAAAACDCe50XuNCZyJ1LK8zyTrHuFaRyHDBmi8dChQ52+kiVL5vuYuXPnOu1OnTolP7EIwj6O+/fvd9qRxuBvf/ub0161apXG8+bNc/pWr16dpOySJ+zjWFgwjuHAOIYD4xgOhW0cq1WrpvE777yj8aZNm5zr2rRpo/GPP/6Y+sQKKNo48s0iAAAAACCAySIAAAAAICDnjs646qqrnPa0adM0njhxosZ33HGHc93hw4dTmxiS5pRTTtF4zJgxTt/VV1+tcbQSatuBAweSkxhExD2ypHjx4k5fpDHp1atXxHbv3r2dvmbNmmn89ddfJ5wn0qtv375O+5lnntHY/nfRqlUr57qFCxemNjEAjqVLl2pcs2ZNp69q1appzqZwuvvuuzXu0qWL03f++efHdI/FixdrfM455zh9ixYtinh/FMzWrVs1njp1qsbDhw93rrPHccWKFalPLIX4ZhEAAAAAEMBkEQAAAAAQkHNlqBdccIHTtncYGjBggMYvvfSSc92SJUtSmxiSpkePHhr37NmzwPfzlySjYH77299qfMwx7n9vev311zXetWtXxHt06NBB4zp16jh9L7zwgsZt27ZNOE+kXpEiRTS+5JJLnL5Iu78NHjzYaVOGmnn9+vXT2C4z99u2bZvGr732Wsz3t0vNZ86cqfHkyZNjvgeSx196ivQYMWKExsOGDdPYv3wj1iU2F110kcb+5TaPPvpoAhkiXvYY+JUqVSqNmaQW3ywCAAAAAAKYLAIAAAAAApgsAgAAAAACcm7N4s6dO2O6zl5XJSLy0UcfacxRCtnn3nvv1XjIkCEJ3cPeDtw+mmHHjh2JJ4aAZcuWaTx06FCn7+OPP9Y42rqLkiVLavzggw86fbfeeqvGv/vd7zR+7LHH4k8WKXXGGWdobK81jub7779PVTrwKV26tMb29vn33HOPc93pp5+ucazrpfzryY0xMd2jZcuWEe9x6aWXxvTciJ/9916xYkWNp0yZkol0CoXjjjvOaXfv3j1lz1WiRAmnffzxx6fsufAz+/gS/7FQN910k8a5vjafbxYBAAAAAAFMFgEAAAAAATlXhurfDvjLL7/U2N6Gu0+fPs51jzzyiMbr1q1LUXZIlL2d/rHHHhvxur1792q8YsUKp+/666/XePv27clLDs4W0PZrcN++fc51sZaw2aXgb775ptN32223aVy7du248kTyVa5cWWN/2WD//v3jvt+sWbMKnBPyV79+faf9zDPPaNygQYN0p5OvYsWKadyiRYvMJRJyp512mtP+29/+pnHRoj9/9LOPMkFyVapUyWmfcsopcd/D/owr4n7uqVKlisYNGzaM+94ouGhHZzz//PPpSyTF+GYRAAAAABDAZBEAAAAAEMBkEQAAAAAQkHNrFg8dOuS0p0+frrF9XEazZs2c63r37q3xXXfdlaLsEKt27do57WjrFG32ugv7iAWkVr9+/TS21xEOGDCgwPdu3bp1ge+B5GrUqJHG9ntn3759netiXaNqGz16tNO2tx7/4osv4r5fYde5c2eNp06d6vTZa41Tbfbs2RrbRyGJuGtbE1nnividd955Trtq1aoa269bjpZKnY0bNzrtxo0ba2yv//7000+d69avX6/xli1bnL5t27Zp/Nxzz2nMmsXsY++/sGDBggxmUnB8swgAAAAACGCyCAAAAAAIyLkyVL+DBw9qvHv37ojX+bcwRvp16dJFY7ucVCRyGeo///lPp3377bcnPzH8on/9618ajx8/XuMOHTo419nHlyxcuDDi/dq2bauxvyzNPlZj0qRJceeKgrNLvK+88sqE7mG/H9ulpk888YRzHaWn8atVq5bGr7zyisaJlAWLiBhjNPb/Hn311Vc1XrJkicb2sRwiIsOGDdN4zZo1Tl+PHj3yfa6nnnoqoXyRvxNPPFFjf0my/W/Dfj36xwqps3r1ao3vueeeAt/vpJNO0th+XQHJxjeLAAAAAIAAJosAAAAAgICcL0O1LVu2TOOOHTtmMBPkx95VMdrup5999pnGdumqiFt2XLp0aafv1FNPjSmP//3vfxqvW7cupscUdh999JHG9t9ZnTp1nOvsHb+6du2q8SeffOJcN27cOI2LFCni9NllUXbZDtLn2muv1bhTp04alylTJuZ72DtiPvnkk8lJrJDq1q2b0/7zn/+ssV1emGgZql162r17d6fvrbfe0rhFixYaz5o1y7nOfq1Wr17d6StevHiBc0RQsWLFnLZd2mj/nYu479u9evXS2P59iNxiLwPhdZU+1apV0zjWz525jm8WAQAAAAABTBYBAAAAAAFMFgEAAAAAAaFas2hvB43sULdu3XzjaPbv36/xzp07nT577VPlypWdPnttVTR79uzR2H8swBtvvBHTPQobe03TpZdeqrG9vlTEXYs6e/bshJ6rb9++CT0OmbVlyxanPWXKlAxlEg6/+c1vNPYfg+Bfj/aT0aNHO+3mzZtrfPHFF2v87rvvOtfZ64u/++67iDlt3rxZ44EDB0a8rmXLlk77uOOOy/c6+5gcxO+ss85y2rfddlvEa1u1aqXxjh07UpZTWJx99tlO214f6n+N+N/7MuHQoUNO2//ZCcmzdetWjTdt2qTxaaedlol00oJvFgEAAAAAAUwWAQAAAAABoSpDRfa55pprNK5Ro0ZMj6lXr57GR44ccfqOOebn/77x448/JpRT2bJlNZ43b57TV758eY3t0kv8bPv27Rr7S3Xee+89jatUqRLT/fxj8PHHHxcgOyTDjTfeqLF/e/5Ixo8f77T37t2b1JzC7sQTT3TaI0eO1DhS2amI+/dul52KuKWnb775psb+8vtY3+vsMtRorr/++oh99tE4/rJZxOdPf/qT0zbGaLxkyRKnj9LT/N1xxx0a26+LM844w7nO/uzh/1xiH+n1+eefa2wfOyMiMm3aNI1j/T3nP2YsUqmx/5ip999/P6b7A7Hgm0UAAAAAQACTRQAAAABAQKjKUKtVq5bpFOBjl3V4nlfg+9mlp8m4n9/QoUM1vvvuu5N+/7DZuHGj07ZLX2LdnXbt2rVOOxXjiviMGjVK42glkPv27dN4+fLlKc0p7PwlhQ0aNNDYLv0WERkzZozG33//vcaDBw92rrN3PbXfizNZYv/VV19lRR65qkWLFhqff/75Tp/998mu0vmzl7mIiAwbNkzjUqVKxXQPu9xXRKR06dIaV6xYUeNzzz3Xue66667TeNmyZRo/8MADznUffPCBxm3atHH6HnrooXxzspf8AMnGN4sAAAAAgAAmiwAAAACAACaLAAAAAICAUK1Z7NmzZ6ZTKJTsOv+OHTs6fXb9fjIcOnRI4/379zt9f/nLXzS2a/4nTpwYc0720Rn4ZS1btozajoX/dfvNN99ovGrVKo3nzp0b970Rm969ezvtypUr53vd4cOHnfYll1yi8Ycffpj8xELuoosu0rhz584Rr9uwYYPTnjRpksb2Om7/Vv32uuEDBw4knGcs7KNyateu7fTZa7z8673wy0qWLKnxPffco7F9nIOIe3TRunXrUp9YDmrfvr3TttcbLliwQGP7SA0R97PHrl27It7z0ksv1bhZs2bOdSeffLLGV1xxhcZdunSJKXc/+3iUnTt3JnQPIBZ8swgAAAAACGCyCAAAAAAICFUZKtKjevXqTnvWrFka//rXvy7w/b/88kuNJ0+e7PTZ5aWzZ8+O6X7+bamjlaH6S08QZJeazpkzx+mzy6Vszz//vNO2S+datWrl9NnHAtjHaHTt2tW5zv53h4Jp3bq10450fMm3337rtO3XI+I3bdo0jf1/5z/88IPGjz/+uNNXq1Ytje2S1CFDhjjXpbr01DZ69GiN7ZJUEfffyaBBg9KWU1jceeedGtvvl5999plz3dVXX522nHLVnj17nPb//vc/jVesWKHxmjVrnOvKli2rsV1OKiJy3HHHafz6669r7C9DjfS+muhxUd26ddPYXxqLzHvuuecynULS8M0iAAAAACCAySIAAAAAIIDJIgAAAAAgoNCsWTz77LM1trdKFhHZt29futPJaTVq1HDayVinaK93efrppzVOdDvo/v37a+xfP4OCWbhwYUzXPfnkkxoPHDjQ6Tty5IjGdevWdfqWLl2qcZkyZTT2r1m016wmuuajMGvYsKHG/u3kbd99953Gbdu2TWlOhU3VqlU19v8bfvvttzW213GLiCxevFjjSMecpELx4sU1vvnmm52+66+/XmP/n8U+9ubjjz9OTXIhUqdOHad900035XvdlClTnLZ/PR6Cpk+f7rTvuusuje+77z6Nzz//fOe6Cy64QGP/vgeZ+v1j7wXQvXt3p2/v3r1pzgZ+YTrOhG8WAQAAAAABTBYBAAAAAAGhKkMdP368xh07dnT6ihYN1R81dIwxGttlb372FtXly5d3+nr37q1xjx49NI429t9//73Tto90QP6aNGmisV2W5vfGG29obJed+q1evdppX3755Rq/+uqrGvfq1cu5zj7mJEzlHunSuHFjje3Xld+oUaM0XrVqVUpzws/s4yb8SyV69uyZtjxq1qyp8T333KOx/X7rZ/+bERF5+eWXk55XmPk/v9ilxosWLdJ47Nix6UopNHbv3u20P/nkE43tIzHatWuX9Oe2P2988cUXGvvfVz/88EON7eUCIu6SAXtZgP81Zh+rQUkqCopvFgEAAAAAAUwWAQAAAAABoarNjFZCaO/Axu6n2ccub7LLnrZt2+Zcd+6552rcunXrhJ7LLgXxl/tQrvHLqlevrnGRIkWcvm+//VZjuww1HnaZ1WOPPaaxvVMdEtOlSxeN77///pgeM3ny5FSlgyjsMk//7zZ79+hkuPXWWzW2y8BF3N2uTzjhhIj3ePfddzV+8cUXnb4NGzYUNMXQK1asmMadOnWKeN20adM0ZtlE/A4fPuy07bJOewdUf6l3iRIlNPbvTvzpp59qvH79+ojPbT8u0deEvSv4Sy+9pLH/89CYMWM0tnd8FRE5ePBgQs+NPCeddJLG9o7WYcY3iwAAAACAACaLAAAAAIAAJosAAAAAgIBQrVlEOPiPSLDZR2x4npfQ/d9++22Nly9fntA9kD97TOz1NP61jfY4nnLKKU6fveX3oEGDkp1ioWb/fUY7LuOhhx7SmPUtqWOvny5XrpzTZ78u+vXr5/TZa2aefvppjX/1q18510Va133OOec47ebNm2scbR3c+++/r/HUqVOdvj/96U8RH4df1qFDB43t44lERN566y2Nn3322bTlVBjYaxiXLl2ab5xNZs6cqbG918O9997rXDdgwACNDx065PTZx04hfqeeeqrGZ555psb255qw4ZtFAAAAAEAAk0UAAAAAQEChKUOtUqWKxsWLF3f6/F/RI7pVq1Y57bZt22o8btw4p88udbOPxEiFzz//XONdu3Zp7C/PyNbyklxhl+76XzsVK1bU+IcfftD4gw8+cK6zy+XKly8f0/POnz/fadtjjPw1aNDAadevXz+mx02cOFHjI0eOJDUn/Mzetn/WrFlOX6VKlTS2f3+JiPTv31/jW265ReNES/Pt0lP76BoRkXnz5mk8ZcoUjb/66quEngv5a9q0qcb+crZ//etf6U4HOeCBBx7QuEePHk5fvXr1NL7tttucPruUlaU4yZPo+28u4JtFAAAAAEAAk0UAAAAAQACTRQAAAABAQKFZs2hvjxzmuuJ02L17t9O2j6I499xznb4aNWpo3K5dO407derkXNemTZu489iwYYPT7tixY8Q+JM+WLVs0trf+FxE58cQT831Mw4YNY76/vQ7SXqd49dVXO9cdOHAg5nsWVv4t+EuXLp3vdZ9++qnT5u82PVasWKGx/f4lIjJixAiN/eN4/PHH53s/e52wiPtevX37do1nz57tXGcfe+F/Tdu/O5E6Xbt21dj/GWXTpk3pTgc5pk+fPk77n//8p8b+fTrsa1mzGD97fXFhwTeLAAAAAIAAJosAAAAAgIBCU4b69ddfa0xZTfrYJYuTJk3KN0bu6ty5s9OeO3euxtGOxLBLTV944QWn791339XY3qofsalbt67GDz/8cEyPsY/KEOFYkkz48MMPnfZll12msX2MhohI8+bN873H1q1bnTYlZtmtUaNGGp988ska79u3z7lu4cKFacsJuWnlypVO217CYS8BQsHZR4/YywemTp3qXGeXAuc6vlkEAAAAAAQwWQQAAAAABISqDNUuuXn88cedvrJly6Y7HSD0/GVuFStWzFAm+MnatWs1fvDBB52+++67T+N169Zp/Pe//z31iSFhX331ldN++eWXM5QJksnehfidd97ReN68ec5169evT1tOyE0//vij07aXeiC5Nm/erHHLli0zl0ga8c0iAAAAACCAySIAAAAAIIDJIgAAAAAgwHieF7nTmMidSCnP80yy7sU4Zg7jGA6MYzgwjuHAOIYD4xgOjGM4RBtHvlkEAAAAAAQwWQQAAAAABDBZBAAAAAAEMFkEAAAAAAQwWQQAAAAABDBZBAAAAAAEMFkEAAAAAAQwWQQAAAAABDBZBAAAAAAEGM/zMp0DAAAAACDL8M0iAAAAACCAySIAAAAAIIDJIgAAAAAggMkiAAAAACCAySIAAAAAIIDJIgAAAAAggMkiAAAAACCAySIAAAAAICB0k0VjTDNjzGxjzBZjjGeMuTfTOSF+xpjSxpg/GmM2GmMOGmP+bYzplum8EDtjzLXGmA+NMd8ZYw4YY9YaYwYbY0ymc0PsjDF3GGOWHR3H740xi40x7TKdF+JnjGlvjFlpjPnBGLPZGDM40zkhfnzOyX3GmBFHx87/v1qZzg3xKQyfV4tmOoEUKCMia0TkRRF5NMO5IHHPiEgjEeknIhtFpL2ITDPG7PY8742MZoZYfSki94vIJyLyg4hcLCJPicgREZmYwbwQn0tE5M8i8k8R2S8iN4rIHGNMc8/zlmQ0M8TMGNNQRGaLyDgR6SkiF4rI08aY/Z7nPZ3R5BAvPueEw2YRaez72VcZyAMFE/rPq8bzvEznkDLGmM0i8pzneaMznQtiZ4wpISJ7RORaz/OmWz+fLSLlPM9rnrHkUCDGmFdFRDzP65LpXJA4Y8wqEXnT87zbM50LYmOMeVFEanqe18T62cMi0t3zvJoZSwwFwuec3GSMGSEi13iexzeJOaywfF4NXRkqQqGYiBQRkYO+nx8QkUbGmGLpTwkFYfJcICJNRWRhpvNB4owxx4hIWRHZl+lcEJemIjLf97P5IlLDGFMtA/kAhV01Y8zWo/+bZ4xp8ssPQZYpFJ9XmSwi63iet0dElojIPcaYmsaYY4wxvxGRTiJSXEROyGiCiJkx5nhjzF7JK0NdKiKPe573WIbTQsEMFZFykld6g9xRRUR2+n620+oDkD7vi0hvEekgeWXh34jIe8aY1hnNCnEpLJ9Xw7hmEeFwjYg8J3n13z9K3rq350TktqNt5IY9IlJfREqJSBMRecAYs93zvMmZTQuJMMbcInmTxcs9z9ua6XwAIBd5nvcP34/eO/oN/x0i8mYGUkLiQv95lW8WkZU8z9vieV5ryVvIf4rneWdL3tf6u4UF4DnD87wfPc/b4HneqqObaDwkImMynRfiZ4z5g4g8LHkTxbcynQ/itkNEKvt+dpLVByCzlolIzUwngfgUhs+rTBaR1TzP2+953nZjTHER6SYiszzPC8V/qSmkjhGREplOAvExxowSkeEi0p6JYs5aIiJtfT9rJyJb+JYYyAoNROS/mU4CiQnz59XQlaEaY8qIyE+7SxUXkcrGmPoistfzvA2ZywzxOFq3X1xE1opIdREZJSIlJa8EDjnAGDNSRN6TvNKMYiLSTETuEpG/ZDIvxMcY86jkbQneU0Q+Mcb89O3UAc/zdmUuM8RpgogsNcaMEZG/St7RGQNEZFBGs0Lc+JyT+4wxj4jIHMk7PqOsiPQVkdaSt9YNOaQwfF4N3dEZxpgWkv9ui+94ntcivdkgUcaYriLyRxE5RUT2isgCERnied6WjCaGmBljJojIZSJysuTtFLZR8s7re9rzvCOZzA2xM8ZE+iUxxfO869OZCwrGGNNBRMaKSB3J29xmoud5j2Q2K8SLzzm5zxgzTfLOHq4kIrtEZJWIjPU87/8ymhjiVhg+r4ZusggAAAAAKDjWLAIAAAAAApgsAgAAAAACmCwCAAAAAAKYLAIAAAAAAqIenRFlFzykmOd5Jln3Yhwzh3EMB8YxHBjHcGAcw4FxDAfGMRyijSPfLAIAAAAAApgsAgAAAAACmCwCAAAAAAKYLAIAAAAAApgsAgAAAAACmCwCAAAAAAKYLAIAAAAAApgsAgAAAAACmCwCAAAAAAKYLAIAAAAAApgsAgAAAAACmCwCAAAAAAKYLAIAAAAAAopmOgEA2a9mzZoa33rrrRqXKVPGue6qq67SeOXKlRqvW7fOue67777TeOzYsU7f3r17C5QrYmOP6W9+85uI1z3yyCMaH3vssRGvs/9diIjs3LlT41dffTWBDFFQPXr00Pj3v/+9xo0bN3au8zxPY2NMxL6mTZtqvHz58qTlifSqUKGCxvPnz3f6Pv74Y4379u2btpwAZC++WQQAAAAABDBZBAAAAAAEGLvEJNBpTOTOLLRw4cKIfS1btkxjJgXneZ755atik2vjGCa5Oo69e/d22uPGjdO4fPnySX2u2bNnO+0rr7xS40OHDiX1uRKVq+NYtKi70mD48OEa9+rVS+MaNWoU+Ln85Yv79u3T2C6HnDdvXoGfK1HZPI4zZsxw2hMmTNA41pLPQYMGOW37dfvjjz9qfMwx7n8njrVv+/btGtuv03hyTIZsHsdcYJed/+Mf/3D6Hn30UY39/56SjXEMB8YxHKKNI98sAgAAAAACmCwCAAAAAAJCVYYa7c+yaNEijXOhJJWv9cMhm8exVq1aTtsuR/L32SWGR44c0Xjjxo3OddOnT9fY3vH0zDPPdK678cYbI+Zl79L5+eefR7wunbJ5HP3q1Kmj8ahRo5y+rl275vsYu2RUROTll1/W+M0334zpeSdPnuy07Z1T/+///k/jyy67zLnu4MGDMd0/GbJtHO3S0+7duzt99u+zIkWKRLyHXSbq/x1ov25j3fE01j7/c6Vzp9RsG8dcY/6zqpcAABPySURBVJea3nDDDU5fgwYNNN6wYUNK82AcwyGM42gvxenXr5/TV7lyZY3t0vwnn3zSue6FF15IUXapQRkqAAAAACAuTBYBAAAAAAFMFgEAAAAAAUV/+ZLsNmLEiJiua9GiRcTHxHoPJE/FihWddqlSpTTu06ePxscdd5xzXYcOHTSuXbt2xPvb27/ba3p+if24119/XeNPP/3Uue7ZZ5/VeN26dTHfP5v4t0z3r1O0vf/++xrfeeedGr/zzjsJPbc9/l26dHH6Zs2apXH79u013rlzZ0LPVdiccMIJGkdao+jnPwYhkeMtypUr57SfeOIJje31bM2bN3euW7BgQdzPlcsaNWqk8YUXXqixfw1grO9b9uP8j7Hfz8aPH6+x/XoWEfn973+vcZMmTSLmEe191V5/mcljNZC/1q1ba/y73/1O4yVLljjXpXqdIoL8RxfZa/orVaoU8XF2X+fOnZ2+xYsXa7x27VqnL9a1zK+88orGheF9un///ho//vjjGu/YscO5bvXq1RqfdNJJGj///PPOdcWKFYvYl2v4ZhEAAAAAEMBkEQAAAAAQkPNHZ9jlpcOHD8/3534jR4502tlYhhqWrYirVq2q8XXXXaex/XW/iMjJJ5+c7+OjbeMeTbQt3pPxOLssoXr16hGvy7ZxHDdunMaDBw+OeJ2/5LNdu3Yar1q1qqBpSL169TT2l8QVL15cY7vsOJHSyGTJtnGM5uyzz9Z4/vz5Tp/9erR17NjRaSfyd/3tt9867eOPP17jXbt2aVyhQoW4750s2TCOkcpGo73XRTs6Y9CgQRpPmDAhkZQcdpmsiFtear/XxXpMh0j0/BORDeOYa55++mmN7aMABg4c6Fw3ceLEtOUUlnG0jyu66aabNLbLOEXc0lCbPTYibhlqokfZROv75ptv8s2xWbNmznX2+9M555yTb+5H75+T4+g/rsg+6mLr1q0a2yXcIiKfffaZxvbnFf9ypU2bNmkcbU6SLTg6AwAAAAAQFyaLAAAAAIAAJosAAAAAgICcPzpj0aJFGttrFpEZzzzzjNO+9NJLNba3h45nHWGs5s6dq/GBAwcSuod9hId9bIOfvzY9V9hbaEdblzZkyBCnnYx1ipHut2LFCqfv4osvTupzFTb/+c9/NL7sssucvipVquT7mA8//DCme9vrM0Tc9XL+ozPs1/iTTz4Z0/0LA3sdUKRjKfx90SRjnaLNf8yFfQyGfcxCtGM64jmuCKnRt29fp92zZ0+NP/jgA4396+Xwy0qXLu20x4wZo/EVV1yhca9evZzr7GMWbP/973+dtv35xV5fKCIyadKkiH2x8n9OK6z867OLFv15SmT/HrXXKPodOnRI47Zt2zp9S5cujdhnHzt28ODBGDPOHL5ZBAAAAAAEMFkEAAAAAATkfBmqzf5aNxe2qQ0Lu9zlmmuucfr8ZWuRrF+/XmO7nDSebbzt4yyOHDkS8+NsdhmCXYbq3wK7QYMGCd0/0yZPnpxvjHBauXJl1Ha8Tj/9dKc9duzYmB63Zs2aAj1vmPjLTX/i3yI/0nXpZpel2iXjF154oXOdnb8/d7vcy1/miuQpX768xg8++KDTV6ZMGY2nTJmi8Q8//JD6xELAPh7DLjsVEenUqZPGdgl2rO+P/vvNnDlT46+//trp87cRnxIlSmjsX6Zx+PBhje1jxmK1bt06p20vxfAv+7GP7Bs1alTcz5Vu2fHbCAAAAACQVZgsAgAAAAACQlWGan+ty86oqVO9enWnffvtt2t87LHHOn12SenChQvz/bmIW4aabBUrVnTaN9xwg8b33nuv03f55Zdr/Nprr2l87bXXOtfNmTMnmSmGnn8XTruEzS7vQfapWbOmxn/9618jXucvo7RLyF9++eWk55Wrkr0bajrZO6+++OKLTl+03VBnzJihsb27KiWpBeP/N/PYY49pbJekioj85S9/0fiJJ55IbWIhYO/0LCJy9913a1ypUiWnzy43fOONNzSOZxmNzV/OiOSpVatWvrGIyLZt2zS2l7Ul6h//+IfG/p1xu3XrpjFlqAAAAACAnMRkEQAAAAAQwGQRAAAAABAQqjWLSI+BAwc6bbvu27+t84033qjxl19+mdrELPbayenTpzt9LVu2jPi4++67T2O7Zn3atGlJzC77NW3a1Gl37txZ48qVK2u8detW5zp7C3FbuXLlnLZ9j2jsra2XLVvm9H3//fcx3QMFY2/jXq9evYjXvfrqq07bXg9sb0le2EU6YiJbj86IxJ9ftKMz7HXu1apVS21ihUjdunWdtn101Z49e5y+WI9xQB77s4uIu/eBvUbR3/7qq680PuGEE5zrOPYiu9nHy9ifazds2JDQ/aL93jtw4EBC98yU7P5tBAAAAADICCaLAAAAAICAQlmG2rx580ynkNNq164dsW/SpElOO5Wlp61atXLaFSpU0Piuu+7SuH79+jHfM5VHeOSSZ555xmmfeeaZGcnj5ptv1vj66693+oYNG6bxuHHj0pVSoXPaaafFdN2jjz7qtPft25eKdHKeXbKWa0dn2Pz5RTs6w+7zl/AhPqVKldL4hRdeiHjdAw884LQTLaUrrPxHw9hHZ5QuXTri4+xSYP9xCXap9pgxYzT2jyNHZ6TOpk2bNLaPORERadOmjcb28WjnnXeec12k323t2rVz2t27d4+Yh300Wy7gm0UAAAAAQACTRQAAAABAgIlWEmKMydl6kWh/rkWLFjntaLtjZorneeaXr4pNssfxyJEjTjvSTmAiIk899ZTGdplahw4d/DlqHG2nTPtxTZo0cfqKFy+e7/2i/Vu45ZZbnLa//LKgsnkco7F3PxVx/97tv+drr702pvv5y3vfe++9mB7Xtm1bjf27KNq7/fnLPfzlJQWVq+MYK//rccCAARrbY/DNN984111xxRUav/vuuynKLnmyYRztEk37vcm/G6rdV6RIkUSeKqVmzJjhtO3XoP89N9L7caJ/rmwYx0z5+9//rrH/fe+TTz7RuHXr1k7ff//739QmloBcGsc6depobJcCi4h06dJF46FDh2oc6+vAvzOmvbO0fxfbbCxRzaVxtPl39547d67GJ598ssbbtm1zrvvPf/6jsT2ml1xyiXNdtPe3Fi1aaJwtvzujjSPfLAIAAAAAApgsAgAAAAACmCwCAAAAAAJCtWbRrgFeuHBhxOtGjhzptEeMGJGijBKXzTXgnTp1ctqvvPJKrHloHOv26dHW8URjrwvavn2703f//fdr/Nxzz8V0v0Rl8zgmyh6TokVjO33Hv5W+f91rJHbN/7Rp05y+bt26afz+++87fY0aNYrp/rEK4zjaXn/9dafdvn37fK+z19KIuGOQC7JhHO1/+7EenXHnnXc6fRMmTEjkqZNq+vTpTttePxfrsRrFihVL6LmzYRzTqUqVKhp/9tlnGvv//i6++GKNly9fnvrECijs42ivZRQROeusszS+8cYbNa5Ro4ZzXbS1zPaRG/fdd19S8iyosIxjyZIlNbb3s7jggguc6+z3Ovt90P85ZNSoURqXKVPG6bPHzh7TTGLNIgAAAAAgLkwWAQAAAAABsdWQ5Qi7DBWp8+abbzrtqVOnauwvu/B/9f6TWMtJE32c/fW/XXaKgrPH4PDhwyl9LrtkL1oJZP369Z2+mjVrarx58+aU5JaLSpQooXHDhg019v/92d5++22N+/fvn5rECpGePXtqbJdW+8vN7NJN/xEJL730ksZbt25NdooRVa9ePd9YxM3fX1IbrQ9BpUuXdtr2a9Aulbvhhhuc63Kh9LQw8f/OstuTJk3S+LzzznOumzJlisaVKlVy+oYMGaLxRx99FPG5ED/7CJPx48dHvO7KK6+M6X7Dhg3T2P/+nmt41wYAAAAABDBZBAAAAAAEMFkEAAAAAASEas0i0mP//v1Ou3fv3hr767ztNYvHHXecxn369HGus7cf3rlzp8ZLlixJKEfWKcavcuXKGttr2/z27Nmj8cGDB52+ffv2JT+xo+bMmeO0N23apPGpp57q9N1+++0aDxgwIGU55ZpBgwZpPHr06JgeY68N3b17d9JzKmyWLl2ab9ykSRPnOvuIiQsvvNDps9c62sclpJr9Pu3fTt5eyxzt6Ixoa4GQx17rJCJy5plnarxmzRqNZ8yYkbackFxff/21xgsWLHD67N/FM2fOdPo6d+6s8dChQzVmzWL2sd8TE92nI1vwzSIAAAAAIIDJIgAAAAAgIFRlqM2bN4/puhEjRqQ2kUJs9erVMV3nP37D3k7+1ltvjeke69evd9qUnsZnzJgxTrtfv34aV6hQwen78ssvNba37p4/f75zXSrLUP2lsf7SU5s//8LKX9p4xx135Hudv7R84MCBGu/duzf5iRVi9lEXdglptNJN/7br9rjapawTJkxwrrOP2IiV/0iMRo0aady4cWON/WVV0Y7H2LZtm8avvPJK3DkVBrVq1dL45ptvjnjd1VdfrbH/dYv08B9nccYZZ2i8ePHipD6Xv7y0U6dOSb0/EAu+WQQAAAAABDBZBAAAAAAEhKoMtUWLFplOATGqW7eu0x43bpzG9k5g/vKrQ4cOaXzNNdc4fR999FEyUww9u9RQRKRkyZIar1ixwumzS4Mz9ffcsGHDiH2HDx922g8//HCq08laZ599tsb+3RKPP/74fB8zatQopz158uTkJxYhhyeeeELjcuXKRXxc//79NbZLOcPCv0uo/fr0l3VG2in1xRdfdK6zd7K1y0b976t2n78M1d71NNYdT/19dqns8uXLBXnKli2rsV3eb+8iLiJy1113afzvf/879Ykhqho1ajjtd955R+Pf/va3GvtLrmMtG65Tp47GU6dOdfrs16C9oyqQSnyzCAAAAAAIYLIIAAAAAAhgsggAAAAACAjVmkVktzZt2mj87LPPOn0nnXSSxnZN/pYtW5zrHnzwQY1Zo1gw/rVDLVu21PjXv/6102evD7XX2SxatCjpedlrJ+3n9a+xtM2ZM8dpr1y5Mul55Yry5ctrXLVq1YjXrVu3TuNUH2dw1VVXaWwf0SIi0qxZs5ju8cADD2h87bXXJiexLOI/1uSUU07RuHv37k5fpGM1/Gsb7cfFumYx1j7/c0Xrs8e/MCtSpIjTHjx4sMY33HCDxsuWLXOue+ihh1KbGOKyZs0ap20fbzFlyhSNO3fu7Fz3xhtvaGyvS7SP0PH3+Y+osdv+46+QO/z7dmQ7vlkEAAAAAAQwWQQAAAAABBj/V9xOpzGRO7NQtD+LzV9mk408z0takpkcx2HDhmk8fPhwjaON1bRp0zS+8847nb4dO3YkMbvUy+ZxLF68uNOeN2+exhdddJHTV6xYMY3tbfGXLFniXNerVy+Nv/vuu4jPbZdKXnnllU7fTTfdpHHt2rU19h+P8d5772nsL3NL9pbi2TyOfvbY2Vu6+9mluvbRNSLBMsKf+I9EsDVv3txp2+Nqlxbb/5b8/OWwffr00dge/wMHDkS8RzS5NI6NGjXS2P86s8ch2pEVkfqiHcURa1+05/IfA+J/Hy+oXBpH2+OPP+60b7vtNo03btyosb/sOKxLLnJ1HP3sslH7PeyMM85wrkvk9egfe7sE315KkElhGcdk++abbzS2P/OIiKxevVrjevXqpS2naKKNI98sAgAAAAACmCwCAAAAAAKYLAIAAAAAAlizmKVytQa8Y8eOTnvmzJkaFy3680kt/rFav369xnfffbfGr732WrJTTKtcHcf69es77bFjx2rcrl27dKUha9eu1bhv375O39KlS9OWRy6NY4MGDTS2t3EXETnrrLNS9rz+91X7NX3w4MGIj7v33ns19q/Ni7buNRG5NI42e/2iiHuMjH3ExoUXXuhcZ49Jso/O8L+H/+EPf9B4woQJ+fwpkieXxtF+33rqqaecPvt1cfnll2u8cOHCVKaUNXJpHGNVqlQpjYcMGeL0XXHFFRrb6xn9R4nZaxEnTpyY7BSTLozjmAysWQQAAAAAhBqTRQAAAABAQKEpQ120aJHGLVu2TEM2BZPNX+uXK1fOadulNf5jEGy7d+/WuH///k7f9OnTk5RddsnmcYxH2bJlNT799NM1vuGGG5zr7CMs/P9OIpk9e7bTHjNmjMZ2KaP97yfdcnUcjz32WKdtH0vTqVOnuO+3bds2p22XJ/vLF2fMmKHxt99+G/dzpUKujmM01apV0zjWMtRoZa3RtvHv2bNnvvcTcZccpFoujaNdYugfn8GDB2v81ltvpTKNrJRL44jIGMf8RStDtY9EadiwYdpyioYyVAAAAABAXJgsAgAAAAACQlWGOmLECI2HDx/u9I0cOTLf67JVNn+tb+/2JSKyYMECjRs3bhzxcR988IHG/jKosMrmcUTsGMdwYBzDgXEMB8YxHBjH/EUrQx06dKjGf/zjH9OWUzSUoQIAAAAA4sJkEQAAAAAQwGQRAAAAABAQqjWLYZLNNeAXXXSR037llVc0rlChgtNnH33QqlUrjXfs2JHMlLJWNo8jYsc4hgPjGA6MYzgwjuHAOOZv1qxZGjdt2tTpq1u3rsZffPFF2nKKhjWLAAAAAIC4MFkEAAAAAARQhpqlsvlr/U6dOjltf1mqbeLEiRpv3bo1mWnkhGweR8SOcQwHxjEcGMdwYBzDgXEMB8pQAQAAAABxYbIIAAAAAAhgsggAAAAACGDNYpaiBjwcGMdwYBzDgXEMB8YxHBjHcGAcw4E1iwAAAACAuDBZBAAAAAAERC1DBQAAAAAUTnyzCAAAAAAIYLIIAAAAAAhgsggAAAAACGCyCAAAAAAIYLIIAAAAAAhgsggAAAAACPh/E4wLyzzdnMIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%matplotlib_inline\n",
    "def PlotBatch(data_loader, batch_size = 16):\n",
    "  batch = next(iter(data_loader))  # first batch of data_loader\n",
    "  fig = plt.figure(figsize=(16,4))\n",
    "  for i in range(16):\n",
    "    style.use('ggplot')\n",
    "    fig.add_subplot(2,8,i+1)\n",
    "    temp = batch[i,1:]\n",
    "    plt.imshow(temp.reshape(28,28), cmap='gray')\n",
    "    plt.title(batch[i,0].item())\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "PlotBatch(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fa8a0",
   "metadata": {
    "id": "313fa8a0"
   },
   "outputs": [],
   "source": [
    "def return_params(device, dropout):\n",
    "    '''\n",
    "    all params1, params2, params3 are lists.\n",
    "    my model will be\n",
    "    conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size=(3,3), stride = (1,1), padding=(1,1))\n",
    "    pool = nn.MaxPool2d(kernel_size = (2,2), stride=(2,2))\n",
    "    conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "    fc = nn.Linear(16*7*7, num_classes)\n",
    "    '''\n",
    "    params1 = init_conv_params(in_channels=1, out_channels=8,  kernel_size=(3,3), device=device)\n",
    "    params2 = init_conv_params(in_channels=8, out_channels=16, kernel_size=(3,3), device=device)\n",
    "    params3 = init_dense_params(in_nodes=16*7*7, out_nodes=10, device=device)\n",
    "    #params = params1 + params2 + params3 # i will store my parameters as torch tensors which requires grad, \n",
    "    # required for giving arguments to optimizer for updating \n",
    "    return [params1, params2, params3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bd4b9",
   "metadata": {
    "id": "156bd4b9"
   },
   "outputs": [],
   "source": [
    "def model(x, params, device, dropout=True):\n",
    "    '''\n",
    "    shape of x will be - (batch_size, num_channels, height, width)\n",
    "    '''\n",
    "    # remember x must be casted to device and x must be a tensor, so first form data and dataloaders\n",
    "    x = x.to(device) # casting to the device\n",
    "    #print(\"op.shape = \", x.shape)\n",
    "    op = conv_batch(x, params=params[0], pad_size=(1,1), stride=(1,1), device=device)\n",
    "    #print(\"op.shape = \", op.shape)\n",
    "    op = pool_batch(op, kernel_size=(2,2), pad_size=(0,0), stride=(2,2), mode='max', device=device)\n",
    "    #print(\"op.shape = \", op.shape)\n",
    "    op = conv_batch(op, params=params[1], pad_size=(1,1), stride=(1,1), device=device)\n",
    "    #print(\"op.shape = \", op.shape)\n",
    "    op = pool_batch(op, kernel_size=(2,2), pad_size=(0,0), stride=(2,2), mode='max', device=device)\n",
    "    #print(\"op.shape = \", op.shape)\n",
    "    # now i  have to flattten the input \n",
    "    op = torch.reshape(op, (op.shape[0], op.shape[1]*op.shape[2]*op.shape[3]))\n",
    "    # now i have to pass the above output through the dense layer\n",
    "    op = dense_batch(op, params=params[2], device=device, dropout=dropout)\n",
    "    \n",
    "    return op # shape must be (batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xfcb-qK2TXv-",
   "metadata": {
    "id": "xfcb-qK2TXv-"
   },
   "source": [
    "# Initializing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ixeZem-STPuN",
   "metadata": {
    "id": "ixeZem-STPuN"
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "params = return_params(device, dropout=True)\n",
    "optimizer = torch.optim.Adam(params=params[0]+params[1]+params[2], lr = lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vwtB5gkbVlE0",
   "metadata": {
    "id": "vwtB5gkbVlE0"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y9iJr9wkeSqN",
   "metadata": {
    "id": "y9iJr9wkeSqN"
   },
   "outputs": [],
   "source": [
    "x = torch.randn((32, 1, 28, 28), dtype=torch.float32)\n",
    "a = model(x, params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z_zYQ0b7eZCw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1671387838529,
     "user": {
      "displayName": "code",
      "userId": "04595808719497941504"
     },
     "user_tz": -330
    },
    "id": "z_zYQ0b7eZCw",
    "outputId": "323d9b32-25f4-4c2e-d03c-674a761d8e24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xkgpOm2rTSpv",
   "metadata": {
    "id": "xkgpOm2rTSpv"
   },
   "outputs": [],
   "source": [
    "def train(epoch, batch_size = 32, print_every = 20):\n",
    "  total_loss = 0 # average of losses over all of the batches\n",
    "  acc = []\n",
    "  tic = time()\n",
    "\n",
    "  for i, batch in enumerate(train_dataloader,1):  # i represents number of batches starting from 1\n",
    "    model_input = (batch[:,1:]/255.0).to(device)\n",
    "    model_input = model_input.reshape((model_input.shape[0], 1, 28, 28))\n",
    "    target = (batch[:,0]).to(device)\n",
    "    #print('model_input.shape = ', model_input.shape)\n",
    "    model_output = model(model_input, params, device)\n",
    "    #print('model_output.shape = ', model_output.shape)\n",
    "    loss = criterion(model_output, target)\n",
    "    total_loss+= loss.item()  # as it is just a tensor of 0 dimension, so converting it to a scalar by .item() method\n",
    "    # backpropoagation\n",
    "    optimizer.zero_grad() # making the gradients equal to zero if there are previously any\n",
    "    loss.backward()\n",
    "    optimizer.step()  # updating the gradients\n",
    "\n",
    "    res = model_output.argmax(dim=1)\n",
    "    acc.append((res==target).sum().item()/batch_size) # accuracy over a batch\n",
    "\n",
    "    if i%print_every==0:   # should print something after every 'print_every' no. of batches are processed\n",
    "      print('Epoch [{}] ({}/{}), train_loss = {:.4f}, accuracy = {:.2f}, time = {:.2f} sec'.format(epoch, i, len(train_dataloader), loss.item(), sum(acc)/len(acc), time() - tic ))\n",
    "  return total_loss/len(train_dataloader) # returns average loss of all batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6wokxxlQTSnc",
   "metadata": {
    "id": "6wokxxlQTSnc"
   },
   "outputs": [],
   "source": [
    "def test(epoch, batch_size = 32, print_every = 50):\n",
    "  total_loss = 0\n",
    "  acc = []\n",
    "  tic = time()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader, 0):\n",
    "      model_input = (batch[:,1:]/255.0).to(device)\n",
    "      target = (batch[:,0]).to(device)\n",
    "      model_input = model_input.reshape((model_input.shape[0], 1, 28, 28))\n",
    "\n",
    "      model_output = model(model_input)\n",
    "      loss = criterion(model_output, target)\n",
    "      total_loss+= loss.item()\n",
    "\n",
    "      result = model_output.argmax(dim=1)\n",
    "      acc.append((result==target).sum().item()/target.shape[0]) \n",
    "  print('Epoch: [{}], Test Loss: {:.4f}, Accuracy: {:.2f}, Time: {:.2f} sec'.format(\n",
    "        epoch+1, total_loss/len(test_dataloader), sum(acc)/len(acc), time()-tic\n",
    "    ))\n",
    "  return total_loss/len(test_dataloader) # Returning Average Testing Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6AdvEXI2V9tY",
   "metadata": {
    "id": "6AdvEXI2V9tY"
   },
   "source": [
    "# Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "xOH7G02jTSlS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 62722,
     "status": "error",
     "timestamp": 1671389032262,
     "user": {
      "displayName": "code",
      "userId": "04595808719497941504"
     },
     "user_tz": -330
    },
    "id": "xOH7G02jTSlS",
    "outputId": "52d3bafa-8907-46f4-c2cc-e010dea139c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (1/1050), train_loss = 4.6850, accuracy = 0.25, time = 56.26 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (2/1050), train_loss = 4.0380, accuracy = 0.25, time = 111.31 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (3/1050), train_loss = 5.0845, accuracy = 0.21, time = 166.65 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (4/1050), train_loss = 4.8763, accuracy = 0.17, time = 220.42 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (5/1050), train_loss = 4.4767, accuracy = 0.18, time = 274.20 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (6/1050), train_loss = 3.9240, accuracy = 0.17, time = 327.99 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (7/1050), train_loss = 4.7415, accuracy = 0.16, time = 381.80 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (8/1050), train_loss = 4.2562, accuracy = 0.16, time = 435.52 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (9/1050), train_loss = 3.6776, accuracy = 0.16, time = 489.24 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (10/1050), train_loss = 4.6411, accuracy = 0.15, time = 542.73 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (11/1050), train_loss = 3.9912, accuracy = 0.14, time = 596.43 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (12/1050), train_loss = 3.9175, accuracy = 0.15, time = 649.90 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (13/1050), train_loss = 2.9805, accuracy = 0.16, time = 703.55 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n",
      "model_output.shape =  torch.Size([32, 10])\n",
      "Epoch [1] (14/1050), train_loss = 3.7033, accuracy = 0.16, time = 757.22 sec\n",
      "model_input.shape =  torch.Size([32, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4bd2a1bcbd7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-d66b16737562>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, batch_size, print_every)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_input.shape = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_output.shape = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-8777462efaf8>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(x, params, device, dropout)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print(\"op.shape = \", op.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print(\"op.shape = \", op.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d4aacf934f30>\u001b[0m in \u001b[0;36mconv_batch\u001b[0;34m(x, params, pad_size, stride, device)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0mof\u001b[0m \u001b[0mx\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     '''\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv_single_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d4aacf934f30>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0mof\u001b[0m \u001b[0mx\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     '''\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv_single_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d4aacf934f30>\u001b[0m in \u001b[0;36mconv_single_image\u001b[0;34m(x, params, pad_size, stride, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                         \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0;31m#print('row = ', row)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;31m#print(\"row.shape = \", torch.stack(row).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "for epoch in range(1, 2):\n",
    "  train_loss.append(train(epoch, batch_size=32, print_every=1))\n",
    "  test_loss.append(test(epoch, batch_size=32, print_every=1))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bfdff6",
   "metadata": {
    "id": "Wwks6lfKTSgt"
   },
   "source": [
    "### Working very slow, so i will use standard nn class, but this can be a implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xU-BZiGwTSeT",
   "metadata": {
    "id": "xU-BZiGwTSeT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hzdvazb4TSSu",
   "metadata": {
    "id": "Hzdvazb4TSSu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f53d4f",
   "metadata": {
    "id": "20f53d4f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bd9a8",
   "metadata": {
    "id": "574bd9a8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
